[pytest]
minversion = 6.0
addopts = -m 'not slow and not pending and not legacy_streamlit and not requires_ui'
testpaths = tests/unit tests/integration tests/behavior tests/behavior/features tests/cli tests/ui
bdd_features_base_dir = tests/behavior/features
norecursedirs =
    .git
    .hypothesis
    .mypy_cache
    .venv
    build
    dist
    tests/behavior/archive
python_files = test_*.py *_steps.py
markers =
    behavior: mark behavior (BDD) tests
    integration: mark integration tests
    unit: mark unit tests
    quick: fast-running regression marker
    real_vss: enable actual VSS extension logic
    slow: tests that take a long time to run
    requires_ui: tests that depend on the ui extra (timeout extended to 600s)
    requires_vss: tests that depend on the vss extra
    requires_git: tests that depend on the git extra
    requires_nlp: tests needing NLP resources
    requires_distributed: tests that depend on the distributed extra
    requires_analysis: tests that depend on the analysis extra
    requires_llm: tests that depend on the llm extra
    requires_parsers: tests that depend on the parsers extra
    requires_gpu: tests that depend on the gpu extra
    redis: tests that interact with Redis
    error_recovery: behavior tests verifying recovery paths
    reasoning_modes: behavior tests exploring reasoning strategies
    user_workflows: behavior tests for end-to-end user workflows
    a2a_mcp: behavior tests for A2A MCP integration
    pending: placeholder behavior tests awaiting implementation
    legacy_streamlit: deprecated Streamlit UI scenarios (opt-in)
    # LLM test complexity tiers (based on empirical baselines)
    llm_simple: LLM tests with simple queries (<10s expected, timeout 20s)
    llm_medium: LLM tests with research tasks (10-30s expected, timeout 60s)
    llm_complex: LLM tests with large context (30-60s expected, timeout 120s)
    llm_workflow: Multi-agent orchestration tests (>60s expected, timeout 180s)
